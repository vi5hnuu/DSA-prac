## âš™ï¸ What Is Asymptotic Notation?

Asymptotic notations describe how an algorithm **behaves as input size (n) grows very large** â€” ignoring constants and small terms.

Think of it as the **"long-term growth rate"** of your codeâ€™s execution time or memory usage.

---

## ğŸ§­ The Three Main Notations

Letâ€™s use a simple analogy â€” think of `T(n)` as _time taken by an algorithm_ for input size `n`.

---

### 1ï¸âƒ£ **Big O Notation â€” Upper Bound**

> **Definition:**
> Big O gives the **worst-case upper limit** on how fast your algorithm grows.

Mathematically:
[
T(n) = O(f(n))
]
means there exist constants `c` and `nâ‚€` such that:
[
T(n) â‰¤ c Ã— f(n), âˆ€ n â‰¥ nâ‚€
]

It tells us:

> â€œThis algorithm will never grow faster than f(n) in the long run.â€

**Example:**

```cpp
for(int i=0; i<n; i++) {
   for(int j=0; j<n; j++) {
       // O(1)
   }
}
```

- Inner loop â†’ `O(n)`
- Outer loop â†’ `O(n)`
- Total â†’ `O(n * n)` = **O(nÂ²)**

âœ… So, **time complexity = O(nÂ²)**
It means the algorithmâ€™s runtime grows at most quadratically with input size.

---

### 2ï¸âƒ£ **Î© (Omega) Notation â€” Lower Bound**

> **Definition:**
> Omega gives the **best-case lower limit** of growth.

Mathematically:
[
T(n) = Î©(f(n))
]
means there exist constants `c` and `nâ‚€` such that:
[
T(n) â‰¥ c Ã— f(n), âˆ€ n â‰¥ nâ‚€
]

It tells us:

> â€œThis algorithm will take _at least_ f(n) time.â€

**Example:**

```cpp
for(int i=0; i<n; i++) {
   // O(1)
}
```

âœ… Best and worst case both are **Î©(n)** (linear lower bound).

---

### 3ï¸âƒ£ **Î˜ (Theta) Notation â€” Tight Bound**

> **Definition:**
> Theta gives a **tight bound** â€” both upper and lower.

Mathematically:
[
T(n) = Î˜(f(n))
]
means there exist constants `câ‚`, `câ‚‚`, and `nâ‚€` such that:
[
câ‚ Ã— f(n) â‰¤ T(n) â‰¤ câ‚‚ Ã— f(n), âˆ€ n â‰¥ nâ‚€
]

It tells us:

> â€œThe algorithm grows _exactly_ at the rate of f(n).â€

**Example:**

```cpp
for(int i=0; i<n; i++) {
   // O(1)
}
```

âœ… So, `T(n)` = Î˜(n)
(Both best-case and worst-case are linear.)

---

## ğŸš€ Real-World Analogy

| Notation | Meaning     | Analogy                                                                 |
| -------- | ----------- | ----------------------------------------------------------------------- |
| **O(n)** | Upper bound | Your **maximum salary potential** â€” youâ€™ll never earn beyond this rate. |
| **Î©(n)** | Lower bound | Your **minimum guaranteed income** â€” youâ€™ll at least make this much.    |
| **Î˜(n)** | Tight bound | Your **exact salary range** â€” both upper and lower roughly same.        |

---

## ğŸ“Š Example with Real Function

Suppose:
[
T(n) = 5n^2 + 10n + 100
]

- As `n â†’ âˆ`, the term `5nÂ²` dominates.
- Constants (`5`, `10`, `100`) become negligible.

âœ… Therefore:

- **O(nÂ²)** â†’ Upper bound
- **Î©(nÂ²)** â†’ Lower bound
- **Î˜(nÂ²)** â†’ Tight bound

---

## ğŸ§  Quick Summary Table

| Notation | Type        | Meaning                | Example |
| -------- | ----------- | ---------------------- | ------- |
| O(f(n))  | Upper bound | Worst-case growth rate | `O(nÂ²)` |
| Î©(f(n))  | Lower bound | Best-case growth rate  | `Î©(nÂ²)` |
| Î˜(f(n))  | Tight bound | Exact growth rate      | `Î˜(nÂ²)` |

---

## ğŸ¯ Bonus Visualization

If we graph execution time vs. input size:

```
   |
 T |                O(nÂ²)
 i |           Î˜(nÂ²)
 m |      Î©(nÂ²)
 e |______________________________________
             n â†’ input size
```

---
