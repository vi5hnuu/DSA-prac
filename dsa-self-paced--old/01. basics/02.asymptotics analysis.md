## ⚙️ What Is Asymptotic Notation?

Asymptotic notations describe how an algorithm **behaves as input size (n) grows very large** — ignoring constants and small terms.

Think of it as the **"long-term growth rate"** of your code’s execution time or memory usage.

---

## 🧭 The Three Main Notations

Let’s use a simple analogy — think of `T(n)` as _time taken by an algorithm_ for input size `n`.

---

### 1️⃣ **Big O Notation — Upper Bound**

> **Definition:**
> Big O gives the **worst-case upper limit** on how fast your algorithm grows.

Mathematically:
[
T(n) = O(f(n))
]
means there exist constants `c` and `n₀` such that:
[
T(n) ≤ c × f(n), ∀ n ≥ n₀
]

It tells us:

> “This algorithm will never grow faster than f(n) in the long run.”

**Example:**

```cpp
for(int i=0; i<n; i++) {
   for(int j=0; j<n; j++) {
       // O(1)
   }
}
```

- Inner loop → `O(n)`
- Outer loop → `O(n)`
- Total → `O(n * n)` = **O(n²)**

✅ So, **time complexity = O(n²)**
It means the algorithm’s runtime grows at most quadratically with input size.

---

### 2️⃣ **Ω (Omega) Notation — Lower Bound**

> **Definition:**
> Omega gives the **best-case lower limit** of growth.

Mathematically:
[
T(n) = Ω(f(n))
]
means there exist constants `c` and `n₀` such that:
[
T(n) ≥ c × f(n), ∀ n ≥ n₀
]

It tells us:

> “This algorithm will take _at least_ f(n) time.”

**Example:**

```cpp
for(int i=0; i<n; i++) {
   // O(1)
}
```

✅ Best and worst case both are **Ω(n)** (linear lower bound).

---

### 3️⃣ **Θ (Theta) Notation — Tight Bound**

> **Definition:**
> Theta gives a **tight bound** — both upper and lower.

Mathematically:
[
T(n) = Θ(f(n))
]
means there exist constants `c₁`, `c₂`, and `n₀` such that:
[
c₁ × f(n) ≤ T(n) ≤ c₂ × f(n), ∀ n ≥ n₀
]

It tells us:

> “The algorithm grows _exactly_ at the rate of f(n).”

**Example:**

```cpp
for(int i=0; i<n; i++) {
   // O(1)
}
```

✅ So, `T(n)` = Θ(n)
(Both best-case and worst-case are linear.)

---

## 🚀 Real-World Analogy

| Notation | Meaning     | Analogy                                                                 |
| -------- | ----------- | ----------------------------------------------------------------------- |
| **O(n)** | Upper bound | Your **maximum salary potential** — you’ll never earn beyond this rate. |
| **Ω(n)** | Lower bound | Your **minimum guaranteed income** — you’ll at least make this much.    |
| **Θ(n)** | Tight bound | Your **exact salary range** — both upper and lower roughly same.        |

---

## 📊 Example with Real Function

Suppose:
[
T(n) = 5n^2 + 10n + 100
]

- As `n → ∞`, the term `5n²` dominates.
- Constants (`5`, `10`, `100`) become negligible.

✅ Therefore:

- **O(n²)** → Upper bound
- **Ω(n²)** → Lower bound
- **Θ(n²)** → Tight bound

---

## 🧠 Quick Summary Table

| Notation | Type        | Meaning                | Example |
| -------- | ----------- | ---------------------- | ------- |
| O(f(n))  | Upper bound | Worst-case growth rate | `O(n²)` |
| Ω(f(n))  | Lower bound | Best-case growth rate  | `Ω(n²)` |
| Θ(f(n))  | Tight bound | Exact growth rate      | `Θ(n²)` |

---

## 🎯 Bonus Visualization

If we graph execution time vs. input size:

```
   |
 T |                O(n²)
 i |           Θ(n²)
 m |      Ω(n²)
 e |______________________________________
             n → input size
```

---
